{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL pipeline to create data warehouse of international student immigration to USA\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project generates a data warehouse to allow analytics on international students in the USA. Data from following sources are extracted, transformed and loaded into a data warehouse:\n",
    "* I94 data from DHS, US-Gov\n",
    "* Weather data for different cities (US and global) from Kaggle\n",
    "* Climate data - processed from aforementioned weather data\n",
    "* US city demographics data from OpenSoft\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import col, isnan, when, count, avg, max, min, round\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Many international students come to the USA either for acedmic studies (F1, F2 visa) or vocational training (M1, M2 visa). Often, dependents accompany these students (F2/M2 visa holders). This project aims to prepare a data lake to perform analytics on incoming international students. \n",
    "\n",
    "Questions that are likely to be answered by the analytics team:\n",
    "1. Which cities are preferred by international students?\n",
    "2. Do international students directly arrive at their destination city or do they prefer traveling through busy hubs (often with cheaper tickets; i94 address vs. location of entry)?\n",
    "3. Does city demographics play a role in inernational student's preference? For example, do international students prefer cities with more foreign-born population?\n",
    "4. Do students prefer cities/localities with similar weathers to their origin cities?\n",
    "\n",
    "This analytics pipeline will be utilized by Universities (to tailor their offerings to international students), airlines (for route optimization) and/or real-estate investors (student housing development).\n",
    "\n",
    "#### Data Sources\n",
    "\n",
    "Following data will be aggregated in the data warehouse:\n",
    "1. Student arrivals data. Monthly data snapshot provided by DHS, US gov (from I94 records).\n",
    "2. Demographics data for each US cities. Released during census.\n",
    "3. Weather data for US cities (destination cities for international students) and foreign cities (origin cities for international immigrants; inferred data from I94 records)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Goal: To develop a data warehouse on international students that arrive in the USA.\n",
    "The data warehouse will allow analytics on international student trends, preference, from where most of the students arrive? What is their destination.\n",
    "\n",
    "# Data source:\n",
    "* I94 arrival data from US DHS.\n",
    "* Weather data from Kaggle.\n",
    "* Visa post data from US gov.\n",
    "* US city demographics data.\n",
    "* Student enrolment data from US DoE (still not decided)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "import pandas as pd\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Step 1.1: I94 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "i94_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1.2: Weather Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_df = spark.read.option('header', True).csv('../../data2/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1.3: City data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_city_df = spark.read.option('header', True).option('sep', ';').csv('us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1.4: Visa port code data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "visa_post_code = requests.get('https://fam.state.gov/fam/09FAM/09FAM010205.html')\n",
    "visa_post_code.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "visa_post_df = pd.read_html(visa_post_code.text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94post_code</th>\n",
       "      <th>entry_post_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>YSL</td>\n",
       "      <td>YSLETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>YUI</td>\n",
       "      <td>YUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>YUM</td>\n",
       "      <td>YUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>YXE</td>\n",
       "      <td>SASKATOON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>ZZZ</td>\n",
       "      <td>MEXICO Land (Banco de Mexico)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i94post_code            entry_post_location\n",
       "654          YSL                         YSLETA\n",
       "655          YUI                           YUMA\n",
       "656          YUM                           YUMA\n",
       "657          YXE                      SASKATOON\n",
       "658          ZZZ  MEXICO Land (Banco de Mexico)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = open('I94_SAS_Labels_Descriptions.SAS')\n",
    "page_nos = range(303,962)\n",
    "\n",
    "airport_dict = dict()\n",
    "for pos, lne in enumerate(file):\n",
    "    if pos in page_nos:\n",
    "        lne_split = lne.split('=')\n",
    "        airport_code = lne_split[0].replace('\\'', '').strip()\n",
    "        airport_city = lne_split[1].replace('\\'', '').strip().split(',')[0]\n",
    "        airport_dict[airport_code] = airport_city\n",
    "\n",
    "file.close()\n",
    "visa_port_table = pd.DataFrame([airport_dict]).T.reset_index()\n",
    "visa_port_table.columns = ['i94post_code', 'entry_post_location']\n",
    "visa_port_table.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94post_code</th>\n",
       "      <th>entry_post_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i94post_code entry_post_location\n",
       "428          NYC            NEW YORK"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa_port_table[visa_port_table.i94post_code == 'NYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|i94post_code| entry_post_location|\n",
      "+------------+--------------------+\n",
      "|         .GA|  No PORT Code (.GA)|\n",
      "|         060|   No PORT Code (60)|\n",
      "|         48Y|PINECREEK BORDER ...|\n",
      "|         5KE|           KETCHIKAN|\n",
      "|         5T6|  No PORT Code (5T6)|\n",
      "|         74S|  No PORT Code (74S)|\n",
      "|         888|UNIDENTIFED AIR /...|\n",
      "|         A2A|  No PORT Code (A2A)|\n",
      "|         ABE|            ABERDEEN|\n",
      "|         ABG|              ALBURG|\n",
      "|         ABQ|         ALBUQUERQUE|\n",
      "|         ABS|      ALBURG SPRINGS|\n",
      "|         ACY|POMONA FIELD - AT...|\n",
      "|         ADS|ADDISON AIRPORT- ...|\n",
      "|         ADT|         AMISTAD DAM|\n",
      "|         ADU|  No PORT Code (ADU)|\n",
      "|         ADW|         ANDREWS AFB|\n",
      "|         AFW| FORT WORTH ALLIANCE|\n",
      "|          AG|   No PORT Code (AG)|\n",
      "|         AG0|            MAGNOLIA|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visa_port_table = spark.createDataFrame(visa_port_table)\n",
    "visa_port_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1: I94 Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43366"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading i94 data and getting only data slice for immigrant international students.\n",
    "\n",
    "student_immigration_df = i94_df.filter(i94_df.i94visa == 3)\n",
    "\n",
    "student_immigration_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Checking for columns with Null values\n",
    "\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "student_immigration_df_nullCount = student_immigration_df.select(\n",
    "                    [count(when(isnan(column_title) | col(column_title).isNull(), column_title)).alias(f'NullCount_{column_title}') for column_title in student_immigration_df.columns]\n",
    "                    ).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NullCount_cicid</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_i94yr</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_i94mon</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_i94cit</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_i94res</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_i94port</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_arrdate</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_i94mode</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_i94addr</th>\n",
       "      <td>3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_depdate</th>\n",
       "      <td>13057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_i94bir</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_i94visa</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_dtadfile</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_visapost</th>\n",
       "      <td>3313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_occup</th>\n",
       "      <td>37803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_entdepa</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_entdepd</th>\n",
       "      <td>13051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_entdepu</th>\n",
       "      <td>43307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_matflag</th>\n",
       "      <td>13051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_biryear</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_dtaddto</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_gender</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_insnum</th>\n",
       "      <td>43329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_airline</th>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_admnum</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_fltno</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_visatype</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "NullCount_cicid         0\n",
       "NullCount_i94yr         0\n",
       "NullCount_i94mon        0\n",
       "NullCount_i94cit        0\n",
       "NullCount_i94res        0\n",
       "NullCount_i94port       0\n",
       "NullCount_arrdate       0\n",
       "NullCount_i94mode       2\n",
       "NullCount_i94addr    3126\n",
       "NullCount_depdate   13057\n",
       "NullCount_i94bir        1\n",
       "NullCount_i94visa       0\n",
       "NullCount_count         0\n",
       "NullCount_dtadfile      0\n",
       "NullCount_visapost   3313\n",
       "NullCount_occup     37803\n",
       "NullCount_entdepa       2\n",
       "NullCount_entdepd   13051\n",
       "NullCount_entdepu   43307\n",
       "NullCount_matflag   13051\n",
       "NullCount_biryear       1\n",
       "NullCount_dtaddto      18\n",
       "NullCount_gender        4\n",
       "NullCount_insnum    43329\n",
       "NullCount_airline    3683\n",
       "NullCount_admnum        0\n",
       "NullCount_fltno        14\n",
       "NullCount_visatype      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_immigration_df_nullCount.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43361"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows with Null values in  columns critical for analyzing immigrant student statistics\n",
    "\n",
    "student_immigration_df = student_immigration_df[student_immigration_df.i94mode.isNotNull()]\n",
    "student_immigration_df = student_immigration_df[student_immigration_df.i94bir.isNotNull()]\n",
    "student_immigration_df = student_immigration_df[student_immigration_df.entdepa.isNotNull()]\n",
    "student_immigration_df = student_immigration_df[student_immigration_df.biryear.isNotNull()]\n",
    "student_immigration_df = student_immigration_df[student_immigration_df.gender.isNotNull()]\n",
    "\n",
    "from pyspark.sql import functions\n",
    "\n",
    "student_immigration_df = student_immigration_df.withColumn(\"arrdate_parsed\", functions.expr(\"date_add('1960-1-1', arrdate)\"))\n",
    "student_immigration_df = student_immigration_df.withColumn(\"depdate_parsed\", functions.expr(\"date_add('1960-1-1', depdate)\"))\n",
    "\n",
    "student_immigration_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- arrdate_parsed: date (nullable = true)\n",
      " |-- depdate_parsed: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2: Weather Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8235082"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = weather_df.filter(weather_df.AverageTemperature.isNotNull())\n",
    "weather_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Checking for columns with Null values\n",
    "\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "weather_df_nullCount = weather_df.select(\n",
    "                    [count(when(isnan(column_title) | col(column_title).isNull(), column_title)).alias(f'NullCount_{column_title}') for column_title in weather_df.columns]\n",
    "                    ).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NullCount_dt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_AverageTemperature</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_AverageTemperatureUncertainty</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_City</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_Country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_Latitude</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NullCount_Longitude</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0\n",
       "NullCount_dt                             0\n",
       "NullCount_AverageTemperature             0\n",
       "NullCount_AverageTemperatureUncertainty  0\n",
       "NullCount_City                           0\n",
       "NullCount_Country                        0\n",
       "NullCount_Latitude                       0\n",
       "NullCount_Longitude                      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df_nullCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.3: US City Data Cleaning/Check Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_city_df.filter(us_city_df['Median Age'].isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.4: Visa Post Data Check/Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa_port_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# visa_post_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # Converting 4 column table into 2 column table.\n",
    "\n",
    "# visa_post_df_1 = visa_post_df[[0,1]]\n",
    "# visa_post_df_2 = visa_post_df[[2,3]]\n",
    "# column_headers = ['post', 'code']\n",
    "\n",
    "# visa_post_df_1.columns = column_headers\n",
    "# visa_post_df_2.columns = column_headers\n",
    "# visa_post_df = pd.concat([visa_post_df_1, visa_post_df_2], axis=0, ignore_index=True).dropna()\n",
    "\n",
    "# visa_post_df.drop(labels=0, axis=0, inplace=True)\n",
    "# visa_post_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94post_code</th>\n",
       "      <th>entry_post_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>YUM</td>\n",
       "      <td>YUMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>YXE</td>\n",
       "      <td>SASKATOON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>ZZZ</td>\n",
       "      <td>MEXICO Land (Banco de Mexico)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i94post_code            entry_post_location\n",
       "656          YUM                           YUMA\n",
       "657          YXE                      SASKATOON\n",
       "658          ZZZ  MEXICO Land (Banco de Mexico)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa_port_table.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data is organized into one fact and six dimension tables.\n",
    "1.  **Fact table - Arrivals Table**: This table records all arrivals data for students. This table contains *'cicid'* - immigrant id, *'arrdate'* - arrival date, *'i94yr'* - arrival year, *'i94mon'* - arrival month, *'entdepa'* - arrival flag, *'i94port'* - port of arrival, *'i94mode'* - entry mode, *'airline'* - carrier for arrival by air, *'fltno'* - Flight number, *'admnum'* - admission number.\n",
    "\n",
    "2. **Dimension table - Student Table**: This table has info about students. Colums of this table: *'cicid'* - immigrant id, *'arrdate_parsed'* - arrival date (parsed), *'i94cit'* - immigrant citizenship, *'i94res'* - immigrant's country of residence, *'i94port'* - port of entry, *'i94mode'* - mode of entry, *'i94addr'* - immigrant address, *'depdate_parsed'* - parsed departure date, *'i94bir'* - immigrant birth year, *'i94visa'* - immigrant visa category, *'visapost'* - immigrant visa issuing post, *'dtadfile'* - date added to i94 file, *'entdepa'* - arrival flag,*'entdepd'* - departure flag, *'entdepu'* - update flag, *'matflag'* - match flag, *'biryear'* - birth year, *'dtaddto'* - admitted until (date of expected departure), *'gender'* - immigrant gender, *'insnum'* - INS number, *'visatype'* - visa type.\n",
    "\n",
    "3. **Dimension table - City Table**: Demographic information about US cities.\n",
    "\n",
    "4. **Dimension table - Weather Table**: Daily (historical) weather information of cities.\n",
    "\n",
    "5. **Dimension table - Climate Table**: Monthly climate of all cities in the Weather Table. Derived by averaging historical data in the Weather Table.\n",
    "\n",
    "6. **Dimension Table - Visa Post Code Table**: Table mapping visa post codes into visa issuing port location (US embassy/consulate location)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "city_table = us_city_df.select('City', 'State', 'State Code' ,'Total Population', 'Foreign-born', 'Race', 'Count')\n",
    "city_table = city_table.withColumn('Count', city_table['Count'].cast('int')). \\\n",
    "                        withColumn('Total Population', city_table['Total Population'].cast('int')). \\\n",
    "                        withColumn('Foreign-born', city_table['Foreign-born'].cast('int'))\n",
    "city_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions\n",
    "\n",
    "pv_table_city = city_table.groupBy('City').pivot('Race').sum('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_table_pv = pv_table_city.join(city_table.select('City', 'State', 'Total Population', 'Foreign-born').drop_duplicates(), \n",
    "             on=['City'], \n",
    "             how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+---------------------------------+-----+-------------------------+------------------+------+----------------+------------+\n",
      "|        City|         State|American_Indian_and_Alaska_Native|Asian|Black_or_African-American|Hispanic_or_Latino| White|Total_Population|Foreign_born|\n",
      "+------------+--------------+---------------------------------+-----+-------------------------+------------------+------+----------------+------------+\n",
      "|   Worcester| Massachusetts|                             1917|15932|                    27491|             39000|131898|          184806|       36907|\n",
      "|       Tyler|         Texas|                             1057| 2543|                    26156|             21536| 72728|          103705|        8225|\n",
      "|Saint George|          Utah|                             2406| 1649|                     1376|             10829| 71915|           80207|        4824|\n",
      "|  Charleston|South Carolina|                              633| 2773|                    29998|              3929|104016|          135524|        5767|\n",
      "+------------+--------------+---------------------------------+-----+-------------------------+------------------+------+----------------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_table_pv = city_table_pv.select('City', \n",
    "                     'State',\n",
    "                      city_table_pv['American Indian and Alaska Native'].alias('American_Indian_and_Alaska_Native'),\n",
    "                      'Asian',\n",
    "                      city_table_pv['Black or African-American'].alias('Black_or_African-American'),\n",
    "                      city_table_pv['Hispanic or Latino'].alias('Hispanic_or_Latino'),\n",
    "                      'White',\n",
    "                      city_table_pv['Total Population'].alias('Total_Population'),\n",
    "                      city_table_pv['Foreign-born'].alias('Foreign_born')\n",
    "                    )\n",
    "city_table_pv.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State',\n",
       " 'American_Indian_and_Alaska_Native',\n",
       " 'Asian',\n",
       " 'Black_or_African-American',\n",
       " 'Hispanic_or_Latino',\n",
       " 'White',\n",
       " 'Total_Population',\n",
       " 'Foreign_born']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_table_pv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "\n",
    "weather_df = weather_df.withColumn('date', weather_df.dt.cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, desc\n",
    "\n",
    "weather_df = weather_df.withColumn('year', year('date')). \\\n",
    "                        withColumn('month', month('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, max, min, round\n",
    "climate_table = weather_df.groupby('city', 'month', 'country').agg(round(avg('AverageTemperature'), 2).alias('AvgTempByMonth'),\n",
    "                               round(max('AverageTemperature'), 2).alias('AvgMaxTempInMonth'),\n",
    "                               round(min('AverageTemperature'), 2).alias('AvgMinTempInMonth')).\\\n",
    "                                sort(['city', 'month'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_table.filter(climate_table.country == 'Pakistan').select('city').drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- arrdate_parsed: date (nullable = true)\n",
      " |-- depdate_parsed: date (nullable = true)\n",
      " |-- i94post_code: string (nullable = true)\n",
      " |-- entry_post_location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "student_immigration_df = student_immigration_df.join(visa_port_table, \n",
    "                            student_immigration_df.i94port == visa_port_table.i94post_code,\n",
    "                           how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# student_immigration_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+------+------+-------+-------+-------------------+-------+-------+-----+--------------+\n",
      "|   cicid|arrdate_parsed| i94yr|i94mon|entdepa|i94port|entry_post_location|i94mode|airline|fltno|        admnum|\n",
      "+--------+--------------+------+------+-------+-------+-------------------+-------+-------+-----+--------------+\n",
      "| 79772.0|    2016-04-01|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     PR|00102|9.251260993E10|\n",
      "| 82086.0|    2016-04-01|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     CI|00006|9.249853903E10|\n",
      "| 82087.0|    2016-04-01|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     DL|00938|9.250404273E10|\n",
      "| 82266.0|    2016-04-01|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     CX|00880|9.242060593E10|\n",
      "| 82267.0|    2016-04-01|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     CX|00880|9.242061403E10|\n",
      "|241744.0|    2016-04-02|2016.0|   4.0|      T|    FMY|         FORT MYERS|    1.0|     DL|  109|  6.70933185E8|\n",
      "|241840.0|    2016-04-02|2016.0|   4.0|      T|    FMY|         FORT MYERS|    1.0|     DL|  215|  6.69393185E8|\n",
      "|241841.0|    2016-04-02|2016.0|   4.0|      T|    FMY|         FORT MYERS|    1.0|     AA|  950|  6.70021085E8|\n",
      "|241842.0|    2016-04-02|2016.0|   4.0|      U|    FMY|         FORT MYERS|    1.0|     DL|  403|  3.13865985E8|\n",
      "|241843.0|    2016-04-02|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     CA|00981|9.258049093E10|\n",
      "|241844.0|    2016-04-02|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     AA|00974|9.253145383E10|\n",
      "|241907.0|    2016-04-02|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     MQ|09529|9.255478483E10|\n",
      "|263904.0|    2016-04-02|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     DL|00002|9.258520343E10|\n",
      "|272196.0|    2016-04-02|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     AB|07008|9.256901143E10|\n",
      "|414894.0|    2016-04-02|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     B6|00174|9.258634473E10|\n",
      "|414909.0|    2016-04-02|2016.0|   4.0|      T|    FMY|         FORT MYERS|    1.0|     NK|  142|  6.71996585E8|\n",
      "|415112.0|    2016-04-02|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     B6|01706|9.256257463E10|\n",
      "|425501.0|    2016-04-02|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     DL|00984|9.259476423E10|\n",
      "|426016.0|    2016-04-02|2016.0|   4.0|      T|    FMY|         FORT MYERS|    1.0|     AV|   20|  6.69054085E8|\n",
      "|426496.0|    2016-04-02|2016.0|   4.0|      G|    FMY|         FORT MYERS|    1.0|     AA|01128|9.259706053E10|\n",
      "+--------+--------------+------+------+-------+-------+-------------------+-------+-------+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arrivals_table = student_immigration_df.select('cicid', 'arrdate_parsed', 'i94yr', 'i94mon', 'entdepa', 'i94port', 'entry_post_location',\n",
    "                                              'i94mode', 'airline', 'fltno', 'admnum')\n",
    "arrivals_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "student_table = student_immigration_df.select('cicid', 'arrdate_parsed', 'i94cit', 'i94res', 'i94port', 'entry_post_location',\n",
    "                                              'i94mode', 'i94addr', 'depdate_parsed', 'i94bir', 'i94visa', \n",
    "                                              'visapost', 'dtadfile', 'entdepa','entdepd', 'entdepu', \n",
    "                                              'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'visatype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+------+------+-------+-------------------+-------+-------+--------------+------+-------+--------+--------+-------+-------+-------+-------+-------+-------+------+------+--------+\n",
      "|   cicid|arrdate_parsed|i94cit|i94res|i94port|entry_post_location|i94mode|i94addr|depdate_parsed|i94bir|i94visa|visapost|dtadfile|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender|insnum|visatype|\n",
      "+--------+--------------+------+------+-------+-------------------+-------+-------+--------------+------+-------+--------+--------+-------+-------+-------+-------+-------+-------+------+------+--------+\n",
      "| 79772.0|    2016-04-01| 260.0| 260.0|    FMY|         FORT MYERS|    1.0|     CA|    2016-04-28|  18.0|    3.0|     MNL|20160401|      G|      O|   null|      M| 1998.0|    D/S|     F|  null|      F1|\n",
      "| 82086.0|    2016-04-01| 263.0| 263.0|    FMY|         FORT MYERS|    1.0|     CA|    2016-07-04|  21.0|    3.0|     BNK|20160401|      G|      O|   null|      M| 1995.0|    D/S|     F|  null|      F1|\n",
      "| 82087.0|    2016-04-01| 263.0| 263.0|    FMY|         FORT MYERS|    1.0|     CA|    2016-09-15|  28.0|    3.0|     BNK|20160401|      G|      O|   null|      M| 1988.0|    D/S|     M|  null|      F1|\n",
      "| 82266.0|    2016-04-01| 266.0| 266.0|    FMY|         FORT MYERS|    1.0|     CA|    2016-04-29|  36.0|    3.0|     HCM|20160401|      G|      O|   null|      M| 1980.0|    D/S|     F|  null|      F2|\n",
      "| 82267.0|    2016-04-01| 266.0| 266.0|    FMY|         FORT MYERS|    1.0|     CA|    2016-04-29|   6.0|    3.0|     HCM|20160401|      G|      O|   null|      M| 2010.0|    D/S|     M|  null|      F2|\n",
      "|241744.0|    2016-04-02| 129.0| 129.0|    FMY|         FORT MYERS|    1.0|     NC|    2016-06-09|  18.0|    3.0|     MDD|20160402|      T|      O|   null|      M| 1998.0|    D/S|     F|  null|      F1|\n",
      "|241840.0|    2016-04-02| 129.0| 129.0|    FMY|         FORT MYERS|    1.0|     NY|          null|  19.0|    3.0|     MDD|20160402|      T|   null|   null|   null| 1997.0|    D/S|     M|  null|      F1|\n",
      "|241841.0|    2016-04-02| 129.0| 129.0|    FMY|         FORT MYERS|    1.0|     NY|    2016-04-06|  25.0|    3.0|     MDD|20160402|      T|      Q|   null|      M| 1991.0|    D/S|     M|  null|      F1|\n",
      "|241842.0|    2016-04-02| 129.0| 129.0|    FMY|         FORT MYERS|    1.0|     NY|    2016-05-09|  32.0|    3.0|     MDD|20160402|      U|      O|   null|      M| 1984.0|    D/S|     M|  null|      F1|\n",
      "|241843.0|    2016-04-02| 129.0| 129.0|    FMY|         FORT MYERS|    1.0|     PA|    2016-06-28|  33.0|    3.0|     MDD|20160402|      G|      O|   null|      M| 1983.0|    D/S|     M|  null|      F1|\n",
      "|241844.0|    2016-04-02| 129.0| 129.0|    FMY|         FORT MYERS|    1.0|     RI|    2016-06-06|  22.0|    3.0|     MDD|20160402|      G|      O|   null|      M| 1994.0|    D/S|     M|  null|      F1|\n",
      "|241907.0|    2016-04-02| 129.0| 129.0|    FMY|         FORT MYERS|    1.0|     RI|    2016-06-25|  22.0|    3.0|     MDD|20160402|      G|      O|   null|      M| 1994.0|    D/S|     F|  null|      F1|\n",
      "|263904.0|    2016-04-02| 135.0| 135.0|    FMY|         FORT MYERS|    1.0|     VT|    2016-08-13|  21.0|    3.0|     LND|20160402|      G|      O|   null|      M| 1995.0|    D/S|     M|  null|      F1|\n",
      "|272196.0|    2016-04-02| 148.0| 112.0|    FMY|         FORT MYERS|    1.0|     FL|    2016-06-04|  16.0|    3.0|     FRN|20160402|      G|      O|   null|      M| 2000.0|    D/S|     F|  null|      F1|\n",
      "|414894.0|    2016-04-02| 585.0| 585.0|    FMY|         FORT MYERS|    1.0|     FL|    2016-05-23|  17.0|    3.0|     SDO|20160402|      G|      O|   null|      M| 1999.0|    D/S|     M|  null|      F1|\n",
      "|414909.0|    2016-04-02| 585.0| 585.0|    FMY|         FORT MYERS|    1.0|     FL|          null|  23.0|    3.0|     SDO|20160402|      T|   null|   null|   null| 1993.0|    D/S|     F|  null|      F1|\n",
      "|415112.0|    2016-04-02| 585.0| 585.0|    FMY|         FORT MYERS|    1.0|     FL|    2016-06-04|  16.0|    3.0|     SDO|20160402|      G|      O|   null|      M| 2000.0|    D/S|     M|  null|      F1|\n",
      "|425501.0|    2016-04-02| 691.0| 691.0|    FMY|         FORT MYERS|    1.0|     MA|          null|  29.0|    3.0|     BGT|20160402|      G|   null|   null|   null| 1987.0|    D/S|     F|  null|      F1|\n",
      "|426016.0|    2016-04-02| 691.0| 691.0|    FMY|         FORT MYERS|    1.0|     MA|    2016-04-30|  26.0|    3.0|     BGT|20160402|      T|      O|   null|      M| 1990.0|    D/S|     M|  null|      F1|\n",
      "|426496.0|    2016-04-02| 691.0| 691.0|    FMY|         FORT MYERS|    1.0|     FL|          null|  21.0|    3.0|     BGT|20160402|      G|   null|   null|   null| 1995.0|    D/S|     M|  null|      F1|\n",
      "+--------+--------------+------+------+-------+-------------------+-------+-------+--------------+------+-------+--------+--------+-------+-------+-------+-------+-------+-------+------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student table size is: 43361 x 21\n",
      "Arrivals table size is:  43361 x 10\n",
      "Weather table size is: 8235082 x 10\n",
      "Climate table size is: : 41880 x 6\n",
      "City table size is: : 596 x 9\n"
     ]
    }
   ],
   "source": [
    "# Checking table sizes.\n",
    "    \n",
    "print('Student table size is:', student_table.count(), 'x' , len(student_table.columns))\n",
    "print('Arrivals table size is: ', arrivals_table.count(), 'x' , len(arrivals_table.columns))\n",
    "print('Weather table size is:', weather_df.count(), 'x' , len(weather_df.columns))\n",
    "print('Climate table size is: :', climate_table.count(), 'x' , len(climate_table.columns))\n",
    "print('City table size is: :', city_table_pv.count(), 'x' , len(city_table_pv.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_dir = 'analytics_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "weather_df.write.mode('append').parquet(output_dir + 'weather_table.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "climate_table.write.mode('append').parquet(output_dir + 'climate_table.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_table_pv.write.mode('append').parquet(output_dir + 'city_table.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "student_table.write.mode('append').parquet(output_dir + 'student_table.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arrivals_table.write.mode('append').parquet(output_dir + 'arrivals_table.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# visa_port_table = spark.createDataFrame(visa_port_table)\n",
    "visa_port_table.write.mode('append').parquet(output_dir + 'visa_post_table.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.1 Checking data quality - Weather table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read from parquet\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "weather_read = spark.read.parquet('analytics_data/weather_table.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check schema for proper column types.\n",
    "\n",
    "weather_read.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### *Defining functions to check table(s)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Funcions to check tables.\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "def check_table_pk_entry_presence(pk_col, dataframe):\n",
    "    \"\"\" This function checks for entries in the table. If no entries are present, ValueError is raised.\n",
    "    Input:\n",
    "        pk_column: primary key column\n",
    "        dataframe: pyspark dataframe\n",
    "    \"\"\"\n",
    "    if dataframe.select(pk_col).count() < 1:\n",
    "        raise ValueError('No entries present in the table.')\n",
    "\n",
    "def check_key_null_presence(col_of_interest, dataframe):\n",
    "    \"\"\" This function checks for null entries at the column of interest in the table. ValueError is raised, if null entries are present.\n",
    "    Input:\n",
    "        col_of_interest: Column of interest to check for presence of null entries. If null entries are present, ValueError will be raised.\n",
    "        dataframe: pyspark dataframe\n",
    "    \"\"\"\n",
    "    num_entries = dataframe.select(\n",
    "                    count(when(isnan(col_of_interest) | col(col_of_interest).isNull(), col_of_interest)).alias(f'NullCount_{col_of_interest}')\n",
    "                    ).collect()[0][0]\n",
    "    if num_entries > 0:\n",
    "        raise ValueError(f'Null entries are present in the table: {dataframe}, column: {col_of_interest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table for entries.\n",
      "Checking table for the presence of Null entries in colums where null is not expected.\n"
     ]
    }
   ],
   "source": [
    "# Checking weather table\n",
    "\n",
    "print('Checking table for entries.')\n",
    "check_table_pk_entry_presence(pk_col= 'dt', dataframe= weather_read)\n",
    "print('Checking table for the presence of Null entries in colums where null is not expected.')\n",
    "check_key_null_presence(col_of_interest='AverageTemperature', dataframe=weather_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.2 Check data quality - climate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "climate_read = spark.read.parquet('analytics_data/climate_table.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- AvgTempByMonth: double (nullable = true)\n",
      " |-- AvgMaxTempInMonth: double (nullable = true)\n",
      " |-- AvgMinTempInMonth: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "climate_read.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table for entries.\n",
      "Checking table for the presence of Null entries in colums where null is not expected.\n"
     ]
    }
   ],
   "source": [
    "# Check for entries.\n",
    "\n",
    "print('Checking table for entries.')\n",
    "check_table_pk_entry_presence(pk_col= 'city', dataframe= climate_read)\n",
    "print('Checking table for the presence of Null entries in colums where null is not expected.')\n",
    "check_key_null_presence(col_of_interest='City', dataframe=climate_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.3 Checking data quality - city table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_read = spark.read.parquet('analytics_data/city_table.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- American_Indian_and_Alaska_Native: long (nullable = true)\n",
      " |-- Asian: long (nullable = true)\n",
      " |-- Black_or_African-American: long (nullable = true)\n",
      " |-- Hispanic_or_Latino: long (nullable = true)\n",
      " |-- White: long (nullable = true)\n",
      " |-- Total_Population: integer (nullable = true)\n",
      " |-- Foreign_born: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check schema\n",
    "\n",
    "city_read.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table for entries.\n",
      "Checking table for the presence of Null entries in colums where null is not expected.\n"
     ]
    }
   ],
   "source": [
    "# Check for entries.\n",
    "\n",
    "print('Checking table for entries.')\n",
    "check_table_pk_entry_presence(pk_col= 'city', dataframe= city_read)\n",
    "print('Checking table for the presence of Null entries in colums where null is not expected.')\n",
    "check_key_null_presence(col_of_interest='City', dataframe=city_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.4 Check data quality - arrivals table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arrivals_read = spark.read.parquet('analytics_data/arrivals_table.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- arrdate_parsed: date (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check schema\n",
    "\n",
    "arrivals_read.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table for entries.\n",
      "Checking table for the presence of Null entries in colums where null is not expected.\n"
     ]
    }
   ],
   "source": [
    "# Check for entries.\n",
    "\n",
    "print('Checking table for entries.')\n",
    "check_table_pk_entry_presence(pk_col= 'cicid', dataframe= arrivals_read)\n",
    "print('Checking table for the presence of Null entries in colums where null is not expected.')\n",
    "check_key_null_presence(col_of_interest='cicid', dataframe=arrivals_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.5 Check data quality - students table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "students_read = spark.read.parquet('analytics_data/student_table.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- arrdate_parsed: date (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- entry_post_location: string (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate_parsed: date (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check schema\n",
    "\n",
    "students_read.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table for entries.\n",
      "Checking table for the presence of Null entries in colums where null is not expected.\n"
     ]
    }
   ],
   "source": [
    "# Check for entries.\n",
    "\n",
    "print('Checking table for entries.')\n",
    "check_table_pk_entry_presence(pk_col= 'cicid', dataframe= students_read)\n",
    "print('Checking table for the presence of Null entries in colums where null is not expected.')\n",
    "check_key_null_presence(col_of_interest='cicid', dataframe=students_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.6 Check data quality - visa post table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa_post_read = spark.read.parquet('analytics_data/visa_post_table.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94post_code: string (nullable = true)\n",
      " |-- entry_post_location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visa_post_read.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>\n",
       "# Defining table display style"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>\n",
    "# Defining table display style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "**Arrivals Table** - Source of Data: i94 record from DHS, US-gov\n",
    "\n",
    "| Column | Data Type | Description| key type |\n",
    "| ---    | ---       | ---        | |\n",
    "| cicid  | double    | arrival id  | primary key|\n",
    "| arrdate_parsed   | date    | date of arrival  | |\n",
    "| i94yr  | double    | year of arrival  | |\n",
    "| i94mon  | double    | month of arrival  | |\n",
    "| entdepa  | string    | arrival flag  | |\n",
    "| i94port  | string    | port of entry; 3-letter code  | |\n",
    "| entry_port_location  | string    | port of entry; full city name  | foreign-key to city table, weather table |\n",
    "| i94mode  | double    | mode of entry  | |\n",
    "| airline  | string    | arrival airline  | |\n",
    "| fltno  | string    | arrival airline flight number | |\n",
    "| admnum  | double    | admission number  | |\n",
    "\n",
    "\n",
    "**Student Table** - Source of Data: i94 record from DHS, US-gov\n",
    "\n",
    "| Column | Data Type | Description| key type |\n",
    "| ---    | ---       | ---        | |\n",
    "| cicid  | double    | arrival id  | primary key, also foreign key for Arrivals table|\n",
    "| arrdate_parsed   | date    | date of arrival  | |\n",
    "| i94cit  | double    | Code for immigrant citizenship country  | |\n",
    "| i94res  | double    | Code for immigrant residency country  | |\n",
    "| i94port  | string    | immigrant port of entry; 3-letter code  | |\n",
    "| entry_port_location  | string    | port of entry; full city name  | foreign-key to city table, weather table |\n",
    "| i94mode  | double    | mode of entry  | |\n",
    "| i94addr  | string    | immigrant us address  | |\n",
    "| depdate_parsed   | date    | date of departure  | |\n",
    "| i94bir  | double    | birth year  | |\n",
    "| i94visa  | double    | Visa type  | |\n",
    "| visapost  | string    | visa issuing post  | foreign-key visa post table |\n",
    "| dtadfile  | string    | date added to i94  | |\n",
    "| entdepa  | string    | arrival flag  | |\n",
    "| entdepd  | string    | departure flag  | |\n",
    "| entdepu  | string    | update flag  | |\n",
    "| matflag  | string    | match flag  | |\n",
    "| biryear  | double    | birth year  | |\n",
    "| dtaddto  | string    | expected departure date  | |\n",
    "| gender  | string    | gender  | |\n",
    "| insnum  | string    | ISN number | |\n",
    "| visatype  | string    | Visa type  | |\n",
    "\n",
    "\n",
    "**City Table** - Source of Data: City demographis data from OpenSoft.\n",
    "\n",
    "| Column | Data Type | Description| key type   |\n",
    "| ---    | ---       | ---        |  |\n",
    "| City  | string    | city name  | primary key |\n",
    "| State   | string    | state name  |  |\n",
    "| American_Indian_and_Alaska_Native  | long    | Number of America Indian and Alaska Native  |  |\n",
    "| Asian  | long    |  Number of Asians   |  |\n",
    "| Black_or_African-American | long | Number of Black/or African-americans |  |\n",
    "| Hispanic_or_Latino | long | Hispanic or Latino |  |\n",
    "| White  | string    | Number of White  |  |\n",
    "| Total_Population  | integer    | total population of city  |  |\n",
    "| Foreign_born  | integer    | Foreign_born population of city  |  |\n",
    "\n",
    " \n",
    " **Weather Table**  - Source of Data: City weather data from Kaggle\n",
    "\n",
    "| Column | Data Type | Description| key type |\n",
    "| ---    | ---       | ---        |  |\n",
    "| dt  | string    | date of record  | primary key, foreign key to arrivals table (arrdate_parsed) |\n",
    "| AverageTemperature  | string    | Average daily temperature |  |\n",
    "| City  | string    | city name  |  |\n",
    "| Country  | string    | country name  |  |\n",
    "| Latitude  | string    | city latitude  |  |\n",
    "| Longitude  | string    | city longitude  |  |\n",
    "| date  | date    | date of record, date object  |  |\n",
    "| year  | integer    |  year   |  |\n",
    "| month  | integer    |  month   |  |\n",
    "\n",
    " \n",
    " **Climate Table**  - Source of Data: Data from processing Weather table\n",
    "\n",
    "| Column | Data Type | Description| key type   |\n",
    "| ---    | ---       | ---        |  |\n",
    "| city  | string    | city name  | primary key, foreign key for student table, visa post table, weather table |\n",
    "| month  | integer    |  month   |  |\n",
    "| country   | string    | country name  |  |\n",
    "| AvgTempByMonth  | double    | Average temperature (of daily average temp.) by month  |  |\n",
    "| AvgMaxTempInMonth  | double    | Average temperature (of daily maximum temp.) by month  |  |\n",
    "| AvgMinTempInMonth  | double    | Average temperature (of daily minimum temp.) by month  |  |\n",
    "\n",
    "\n",
    "**Visa post table**  - Source of Data: From US gov Dept. of State website.\n",
    "\n",
    "| Column | Data Type | Description|key type   |\n",
    "| ---    | ---       | ---        |  |\n",
    "| entry_post_location   | string    | city name  | foreign-key for city table |\n",
    "| i94post_code   | string    | 3-letter code for the city of issuing  | primary key, foreign key for students and arrival tables |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.1 Rationale for choice of tools and technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Data was loaded using PySpark and/or pandas.\n",
    "* ETL of small datasets were performed using pandas due to its flexibility (esp. when the dataset can be easily loaded into RAM).\n",
    "* Larger datasets were loaded, transformed in PySpark. PySpark is the preferred tool for the ETL of large datasets. PySpark can utilize distributed computing to analyze large datasets.\n",
    "* After ETL, here, data was stored in parquet format. Parquet format is a compressed format that is widely read by commonly utilized large data analytics tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.2 Data update frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* I94 data will be updated monthly (or at the frequency US gov releases I94 data).\n",
    "* Weather data update frequency will be based on I94 data update frequency.\n",
    "* Climate data update will be yearly.\n",
    "* Visa post data - whenever there is a new entry in i94 that does not correspond to current visa post table code(s).\n",
    "* City demographics data - when new census is released."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.2 Future scenerio planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "*Data increased by 100x*\n",
    "\n",
    "Proper data partitioning scheme has to be implemented. For I94 data tables, we can partition data by year of entry (it is likely that most of the analytics will look into student intake year-by-year basis). For student data table, we can partition data by year of arrival.\n",
    "\n",
    "If partition does not work, then we can use hadoop/Amazon EMR clusters where data will be partitioned and distiributed to multiple nodes. Partitioned data (to each nodes) will be analyzed in-parallel and aggregated using Apache PySpark.\n",
    "\n",
    "*Daily update by 7am every day.*\n",
    "\n",
    "The ETL pipeline can be implemented in Apache Airflow to allow scheduled run at defined times.\n",
    "\n",
    "*Database needed to be accessed by 100+ people*\n",
    "\n",
    "Data lake can be transformed into Amazon Redshift DB. Redshift can easly manage/scale such loads. Also, if the business requirement for the clients are different, then database design can be optimized for each of the client-sets (with database designs optimized for different tasks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.3 Example queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "students_read = spark.read.parquet('analytics_data/student_table.parquet/')\n",
    "arrivals_read = spark.read.parquet('analytics_data/arrivals_table.parquet/')\n",
    "weather_read = spark.read.parquet('analytics_data/weather_table.parquet')\n",
    "city_read = spark.read.parquet('analytics_data/city_table.parquet/')\n",
    "climate_read = spark.read.parquet('analytics_data/climate_table.parquet/')\n",
    "visa_post_read = spark.read.parquet('analytics_data/visa_post_table.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "students_read.createOrReplaceTempView('student_table')\n",
    "arrivals_read.createOrReplaceTempView('arrivals_table')\n",
    "weather_read.createOrReplaceTempView('weather_table')\n",
    "city_read.createOrReplaceTempView('city_table')\n",
    "climate_read.createOrReplaceTempView('climate_table')\n",
    "visa_post_read.createOrReplaceTempView('visa_post_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.3.1 International students and arrival city demographics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|city_avg_foreing_born_percentage|\n",
      "+--------------------------------+\n",
      "|                           18.25|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All city avg foreign born percentage\n",
    "\n",
    "spark.sql(\"select round(avg(pct_foreign_born),2) as city_avg_foreing_born_percentage from \\\n",
    "          (select (Foreign_born/total_population*100) as pct_foreign_born from city_table)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+----------------+\n",
      "|entry_post_location|num_students|pct_foreign_born|\n",
      "+-------------------+------------+----------------+\n",
      "|           NEW YORK|        6122|           37.57|\n",
      "|        LOS ANGELES|        5549|            37.4|\n",
      "|            CHICAGO|        2800|           21.08|\n",
      "|              MIAMI|        2686|           59.14|\n",
      "|      SAN FRANCISCO|        2414|           34.37|\n",
      "|             BOSTON|        2241|            28.4|\n",
      "|            SEATTLE|        1699|           17.51|\n",
      "|            HOUSTON|        1318|           30.29|\n",
      "|    FORT LAUDERDALE|        1201|           26.64|\n",
      "|            ATLANTA|        1162|             6.9|\n",
      "|             DALLAS|        1139|           25.14|\n",
      "|            DETROIT|        1009|            5.89|\n",
      "|            ORLANDO|         983|           18.66|\n",
      "|            PHOENIX|         574|           19.24|\n",
      "|          LAS VEGAS|         563|           20.46|\n",
      "|       PHILADELPHIA|         431|            13.1|\n",
      "|          VANCOUVER|         325|           12.58|\n",
      "|              TAMPA|         247|           15.93|\n",
      "|          SAN DIEGO|         246|            26.8|\n",
      "|             DENVER|         233|           16.59|\n",
      "+-------------------+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\" SELECT l.entry_post_location, l.num_students, round((r.Foreign_born/r.total_population*100),2) as pct_foreign_born \\\n",
    "            FROM \\\n",
    "              (SELECT entry_post_location, count(cicid) as num_students \\\n",
    "              FROM arrivals_table \\\n",
    "              GROUP BY entry_post_location) as l \\\n",
    "            INNER JOIN city_table as r \\\n",
    "            on upper(l.entry_post_location)= upper(r.City) \\\n",
    "            ORDER BY num_students desc \\\n",
    "            LIMIT 20\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Summarized statistics from the city table indicates that ~18.25% of major US cities are foreign-born.\n",
    "\n",
    "A join query on arrivals_table and city_table suggests that top cities where immigrants arrive have >18.25% foreign-born population - suggesting international students often prefer cities with high-foreign-born population.\n",
    "\n",
    "*Point to note*: This enrichment may also be due to high-number of educational institutes in these cities. Education institute/student enrolment data (if available) will shed light into this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
